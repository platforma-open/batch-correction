wf := import("@platforma-sdk/workflow-tengo:workflow")
exec := import("@platforma-sdk/workflow-tengo:exec")
assets:= import("@platforma-sdk/workflow-tengo:assets")
xsv := import("@platforma-sdk/workflow-tengo:pframes.xsv")
pframes := import("@platforma-sdk/workflow-tengo:pframes")

pfUMAPConv := import(":pf-umap-conv")
pfTSNEConv := import(":pf-tsne-conv")
pfPCAConv := import(":pf-pca-conv")
pfRawCountsConv := import(":pf-counts-conv")
pfNormCountsConv := import(":pf-norm-counts-conv")

wf.prepare(func(args){
	metaRefs := {}
	i := 0

	for metaRef in args.covariateRefs {
		metaRefs["metaRef" + i ] = wf.resolve(metaRef, { errIfMissing: true })
		i = i + 1
	}

	return {
		resolvedInput: wf.resolve(args.countsRef, { errIfMissing: true }),
		metaRefs: metaRefs 
	}
})

wf.body(func(args) {

	blockId := wf.blockId().getDataAsJson()
	rawCounts := args.resolvedInput
	inputSpec := rawCounts.spec
	species := inputSpec.domain["pl7.app/species"]

	covariates := []

	for _, v in args.metaRefs {
		covariates = append(covariates, v)
	}
	
	csvCovariates := xsv.exportFrame(covariates, "csv", {})

	csvCounts := xsv.exportFrame([rawCounts], "csv", {})

	batchCorrection := exec.builder().
		software(assets.importSoftware("@platforma-open/milaboratories.batch-correction.software:calculate-batchCorrection")).
		addFile("rawCounts.csv", csvCounts).
		addFile("metadata.csv", csvCovariates).
		arg("--counts").arg("rawCounts.csv").
		arg("--metadata").arg("metadata.csv").
		arg("--output").arg(".").
		saveFile("umap_dimensions.csv").
		saveFile("tsne_dimensions.csv").
		// saveFile("batch_corrected_counts.csv").
		// saveFile("batch_corrected_normalized_counts.csv").
		saveFile("harmony_results.csv").
		printErrStreamToStdout().
		saveStdoutContent().
		cache(24 * 60 * 60 * 1000).
		run()

	UMAPDimImportParams := pfUMAPConv.getColumns(blockId, inputSpec)
	UMAPPf := xsv.importFile(batchCorrection.getFile("umap_dimensions.csv"), "csv", UMAPDimImportParams)

	tSNEDimImportParams := pfTSNEConv.getColumns(blockId, inputSpec)
	tSNEPf := xsv.importFile(batchCorrection.getFile("tsne_dimensions.csv"), "csv", tSNEDimImportParams)

	// batchCorrectedCountsImportParams := pfRawCountsConv.getColumns(blockId, inputSpec, species)
	// batchCorrectedCountsPf := xsv.importFile(batchCorrection.getFile("batch_corrected_counts.csv"), "csv", batchCorrectedCountsImportParams)

	PCADimImportParams := pfPCAConv.getColumns(blockId, inputSpec)
	PCAPf := xsv.importFile(batchCorrection.getFile("harmony_results.csv"), "csv", PCADimImportParams)

	// batchCorrectedNormalizedCountsImportParams := pfNormCountsConv.getColumns(blockId, inputSpec, species)
	// batchCorrectedNormalizedCountsPf := xsv.importFile(batchCorrection.getFile("batch_corrected_normalized_counts.csv"), "csv", batchCorrectedNormalizedCountsImportParams)

	return {
		outputs: {
			UMAPPf: pframes.exportFrame(UMAPPf),
			tSNEPf: pframes.exportFrame(tSNEPf)
		},
		exports: {
			// batchCorrectedrawCounts: {
			// 	spec: batchCorrectedCountsPf["rawCounts.spec"],
			// 	data: batchCorrectedCountsPf["rawCounts.data"]
			// 	},
			UMAP1: {
				spec: UMAPPf["umap1.spec"],
				data: UMAPPf["umap1.data"]
				},
			UMAP2: {
				spec: UMAPPf["umap2.spec"],
				data: UMAPPf["umap2.data"]
				},
			tSNE1 : {
				spec: tSNEPf["tsne1.spec"],
				data: tSNEPf["tsne1.data"]
				},
			tSNE2 : {
				spec: tSNEPf["tsne2.spec"],
				data: tSNEPf["tsne2.data"]
				},
			PCembeddings: {
				spec: PCAPf["pcvalue.spec"],
				data: PCAPf["pcvalue.data"]
				}
		}
	}
})

